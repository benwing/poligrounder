#!/bin/sh

# For directories holding tokenized/preprocessed versions of the Geotext
# Twitter corpus at varying levels of doc_count_thresh (parameter in
# preproc/extract.py in the Geotext corpus).  Assume extract.py has been
# run appropriately with the appropriate value of doc_count_thresh and
# output is in processed-##-docthresh subdir in the corpus.  Generate
# appropriate WikiGrounder-format files in output-##-docthresh subdirs
# one level up from the corpus.
#
# Run this at the top level of the GeoText.####-##-## tree.

DEBUG="--debug 0"

### Standard boilerplate to get config ###

if [ -z "$POLIGROUNDER_DIR" ]; then
  echo "Must set POLIGROUNDER_DIR to top level of TextGrounder distribution"
  exit 1
fi

. $POLIGROUNDER_DIR/bin/config-geolocate

### End boilerplate to get config ###

### Do it ###

# Change list of threshold values if you want; remember, you already
# had to have run extract.py. (FIXME: Old name, what's the new name?)


STEP1="$TG_PYTHON_DIR/twitter_to_lda.py"
STEP2="$TG_PYTHON_DIR/twitter_geotext_process.py"

for x in 5 10 2 20 3; do
  INDIR="processed-$x-docthresh"
  OUTDIR="../../output-$x-docthresh"
  cd $INDIR
  echo "Working in $INDIR"
  # Need to copy files indicating train/dev/test split.
  cp -p ../processed_data/user_info.* .
  echo "Running $STEP1"
  $STEP1 -i . -o .
  mkdir -p $OUTDIR
  echo "Output dir is $OUTDIR"
  echo "Running $STEP2"
  $STEP2 -i . -o $OUTDIR
  cd ..
done
